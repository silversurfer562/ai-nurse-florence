
name: Enhanced Repo Digest

on:
  push:
    branches: ["**"]
  workflow_dispatch: {}  # allow manual runs for debugging

permissions:
  contents: read  # enough for checkout

jobs:
  digest:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Generate digest
        run: |
          python - <<'PY'
          import os, subprocess, datetime, json

          # Safely compute before/after for this run
          before = os.environ.get("GITHUB_EVENT_BEFORE")
          after = os.environ.get("GITHUB_SHA")

          if not after:
            after = subprocess.check_output(["git","rev-parse","HEAD"]).decode().strip()

          if not before or before == "0000000000000000000000000000000000000000":
            # First push or weird event shape: use initial commit as 'before'
            before = subprocess.check_output(["git","rev-list","--max-parents=0","HEAD"]).decode().strip()

          # Collect commits for the range (exclude merges)
          fmt = "%H|%h|%an|%ae|%ad|%s"
          commits_raw = subprocess.check_output(
              ["git","log","--no-merges","--pretty=format:"+fmt, f"{before}..{after}"]
          ).decode().strip().splitlines()

          if not commits_raw:
            # single-commit push
            commits_raw = subprocess.check_output(
                ["git","log","-1","--pretty=format:"+fmt, after]
            ).decode().strip().splitlines()

          commits = []
          for line in commits_raw:
            parts = line.split("|", 5)
            if len(parts) == 6:
              full, short, author, email, date, subject = parts
              commits.append({"full":full,"short":short,"author":author,"email":email,"date":date,"subject":subject})

          # Diff stats & top files
          diffstat = subprocess.check_output(["git","diff","--stat", before, after]).decode()
          files = subprocess.check_output(["git","diff","--numstat", before, after]).decode().strip().splitlines()
          file_rows = []
          for row in files:
            try:
              ins, dele, path = row.split("\t", 2)
              ins = 0 if ins == "-" else int(ins)
              dele = 0 if dele == "-" else int(dele)
              file_rows.append((ins+dele, ins, dele, path))
            except Exception:
              pass
          file_rows.sort(reverse=True)
          top_files = file_rows[:20]

          repo = os.environ.get("GITHUB_REPOSITORY","repo")
          ref = os.environ.get("GITHUB_REF_NAME","branch")
          ts = datetime.datetime.utcnow().strftime("%Y-%m-%d %H:%M UTC")

          # Enhanced markdown with better formatting
          md = []
          md.append(f"# 📊 Repository Digest — {repo}")
          md.append(f"**Branch:** {ref} | **Generated:** {ts}")
          md.append("")
          
          # Summary with emojis
          md.append("## 📈 Summary")
          md.append(f"- 🔄 **Commits in push:** {len(commits)}")
          if file_rows:
            total_chg = sum(n for n,_,_,_ in file_rows)
            md.append(f"- 📁 **Files changed:** {len(file_rows)} files, {total_chg} total line changes")
          md.append("")
          
          # Diffstat
          md.append("## 📋 Diffstat")
          md.append("```diff")
          md.append(diffstat.strip() or "(no changes)")
          md.append("```")
          md.append("")
          
          # Commits with better formatting
          md.append("## 🔀 Commits")
          for i, c in enumerate(commits, 1):
            md.append(f"### {i}. {c['subject']}")
            md.append(f"**Author:** {c['author']} | **Date:** {c['date']}")
            md.append(f"**Link:** https://github.com/{repo}/commit/{c['full']}")
            md.append("")

          # Top files table
          if top_files:
            md.append("## 📂 Top Changed Files")
            md.append("| Rank | File | Additions | Deletions | Total |")
            md.append("|---:|---|---:|---:|---:|")
            for i,(chg,ins,dele,path) in enumerate(top_files, start=1):
              md.append(f"| {i} | `{path}` | +{ins} | -{dele} | {chg} |")
            md.append("")

          # Add metadata for Notion
          metadata = {
            "repository": repo,
            "branch": ref,
            "commit_count": len(commits),
            "files_changed": len(file_rows),
            "total_changes": sum(n for n,_,_,_ in file_rows) if file_rows else 0,
            "timestamp": ts,
            "commits": commits[:5]  # First 5 commits for Notion
          }

          with open("digest.md","w", encoding="utf-8") as f:
            f.write("\n".join(md) + "\n")
          
          with open("digest-metadata.json","w", encoding="utf-8") as f:
            json.dump(metadata, f, indent=2)
            
          print("✓ Generated enhanced digest with metadata")
          PY
        env:
          GITHUB_EVENT_BEFORE: ${{ github.event.before }}

      # Always upload the digest as a build artifact
      - name: Upload digest artifact
        uses: actions/upload-artifact@v4
        with:
          name: repo-digest-${{ github.sha }}
          path: |
            digest.md
            digest-metadata.json

      # ===== Enhanced Notion Integration =====
      - name: Install Notion dependencies
        if: ${{ vars.ENABLE_NOTION == '1' }}
        run: pip install --upgrade requests

      - name: Push Enhanced Digest to Notion
        if: ${{ vars.ENABLE_NOTION == '1' }}
        run: |
          python - <<'PY'
          import os, json, requests
          from datetime import datetime
          
          token = os.environ["NOTION_TOKEN"]
          database_id = os.environ["NOTION_DATABASE_ID"]
          
          # Load content and metadata
          with open("digest.md","r",encoding="utf-8") as f:
            content = f.read()
          with open("digest-metadata.json","r",encoding="utf-8") as f:
            metadata = json.load(f)

          # Create structured Notion page
          def create_rich_text(text):
            return [{"type": "text", "text": {"content": text}}]

          def create_text_block(text):
            return {
              "object": "block",
              "type": "paragraph", 
              "paragraph": {"rich_text": create_rich_text(text)}
            }

          # Create enhanced page properties
          page = {
            "parent": {"database_id": database_id},
            "properties": {
              "Title": {
                "title": create_rich_text(f"📊 Repo Digest — {metadata['branch']} — {datetime.now().strftime('%Y-%m-%d')}")
              },
              "Type": {
                "select": {"name": "Repository Digest"}
              },
              "Repository": {
                "rich_text": create_rich_text(metadata["repository"])
              },
              "Branch": {
                "rich_text": create_rich_text(metadata["branch"])
              },
              "Commit Count": {
                "number": metadata["commit_count"]
              },
              "Date": {
                "date": {"start": datetime.utcnow().isoformat()}
              },
              "URL": {
                "url": f"https://github.com/{metadata['repository']}/commits/{metadata['branch']}"
              }
            },
            "children": []
          }

          # Add summary
          page["children"].append(create_text_block(f"📈 Summary: {metadata['commit_count']} commits, {metadata['files_changed']} files changed, {metadata['total_changes']} total line changes"))
          page["children"].append(create_text_block(""))

          # Add top commits
          if metadata["commits"]:
            page["children"].append(create_text_block("🔀 Recent Commits:"))
            for commit in metadata["commits"]:
              page["children"].append(create_text_block(f"• {commit['subject']} - {commit['author']}"))
          
          # Add full content in chunks
          chunks = [content[i:i+1800] for i in range(0, len(content), 1800)]
          for chunk in chunks:
            page["children"].append(create_text_block(chunk))

          # Send to Notion
          response = requests.post(
            "https://api.notion.com/v1/pages",
            headers={
              "Authorization": f"Bearer {token}",
              "Notion-Version": "2022-06-28",
              "Content-Type": "application/json",
            },
            json=page,
            timeout=30,
          )
          response.raise_for_status()
          
          result = response.json()
          print(f"✓ Created enhanced Notion page: {result.get('id')}")
          print(f"📄 Page URL: {result.get('url', 'N/A')}")
          PY
        env:
          NOTION_TOKEN: ${{ secrets.NOTION_TOKEN }}
          NOTION_DATABASE_ID: ${{ secrets.NOTION_DATABASE_ID }}

      # ===== Email Integration (Optional) =====
      - name: Send Digest Email
        if: ${{ vars.ENABLE_EMAIL == '1' }}
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 465
          secure: true
          username: ${{ secrets.GMAIL_ADDRESS }}
          password: ${{ secrets.GMAIL_APP_PASSWORD }}
          subject: "📊 [Repo Digest] ${{ github.repository }} @ ${{ github.ref_name }}"
          to: ${{ secrets.DIGEST_TO }}
          from: ${{ secrets.GMAIL_ADDRESS }}
          body: |
            📊 New repository digest available for ${{ github.repository }} @ ${{ github.ref_name }}.
            
            🔗 View commit details: https://github.com/${{ github.repository }}/compare/${{ github.event.before }}...${{ github.sha }}
            
            See attached digest for full details.
          attachments: |
            digest.md
            digest-metadata.json
